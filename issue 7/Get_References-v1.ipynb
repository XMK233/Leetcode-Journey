{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2019年7月9日\n",
    "我们要做什么呢？\n",
    "* 首先，为每一个module找到它们的reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ganeval-cifar10-convnet 1 https://aihub.cloud.google.com/p/products%2F110689d8-c594-49d6-aef4-9fc91c9c2ab4\n",
      "faster_rcnn-openimages_v4-inception_resnet_v2 1 https://aihub.cloud.google.com/p/products%2F41b42dfa-e600-4a73-a425-7c5c4d511c3c\n",
      "random-nnlm-en-dim50 1 https://aihub.cloud.google.com/p/products%2Fb0766fd5-82b5-48e3-9d6f-26c5d2601d5f\n",
      "image_augmentation-crop_rotate_color 1 https://aihub.cloud.google.com/p/products%2Fcd9eda73-8cc4-4dbc-aa62-c97e98d657af\n",
      "image_augmentation-nas_svhn 1 https://aihub.cloud.google.com/p/products%2F5eef4456-8aa9-47d7-84db-00a7faa6662a\n",
      "image_augmentation-crop_color 1 https://aihub.cloud.google.com/p/products%2F83bb37d7-5060-4ba7-85e4-6c00a582e789\n",
      "random-nnlm-en-dim128 1 https://aihub.cloud.google.com/p/products%2Fa52e9466-f691-4f91-a62e-f6e39eb967f8\n",
      "image_augmentation-nas_cifar 1 https://aihub.cloud.google.com/p/products%2F822fa7f1-2207-4645-bcab-b7b916dae368\n",
      "image_augmentation-nas_imagenet 1 https://aihub.cloud.google.com/p/products%2Fdaf153b0-cc1b-4f27-a037-5bd3d9fff224\n",
      "image_augmentation-flipx_crop_rotate_color 1 https://aihub.cloud.google.com/p/products%2F2012b39c-9bd7-4670-bbc0-190c89405778\n",
      "openimages_v4-ssd-mobilenet_v2 1 https://aihub.cloud.google.com/p/products%2F8c6878ba-d32d-411d-bac2-2f884b748c4f\n"
     ]
    }
   ],
   "source": [
    "import json, md2py, re\n",
    "from lxml import etree\n",
    "\n",
    "JSON_FILE = r\"J:\\ModelStoreData\\AIHub\\2019-06-04\\TFModule_Info.json\"\n",
    "\n",
    "def beautify_string(paper):\n",
    "    paper = paper.replace(\"\\\"\", \"\")\n",
    "    paper = paper.replace(\"\\n\", \" \").strip()\n",
    "    paper = ' '.join(paper.split())\n",
    "    return paper\n",
    "\n",
    "# def remove_github_items(l):\n",
    "#     for ll in l: \n",
    "#         if \"GitHub issue\" in ll:\n",
    "#             l.remove(ll)\n",
    "#         if \"https://github.com\" in ll:\n",
    "#             l.remove(ll)\n",
    "#     return l\n",
    "\n",
    "def remove_github_items(keywords, l):\n",
    "    removed_index = []\n",
    "    for i in range(len(l)): \n",
    "        if keywords in l[i]:\n",
    "            removed_index.append(i)\n",
    "    for i in sorted(removed_index, reverse=True):\n",
    "        del l[i]\n",
    "    return l\n",
    "#         print(re.findall(\"[G, g]it[H, h]ub\"))\n",
    "\n",
    "paper_link = {}\n",
    "module_link = {}\n",
    "paper_module = {}\n",
    "module_paper = {}\n",
    "module_version = {}\n",
    "\n",
    "def get_reference_info(module, md):\n",
    "    toc = md2py.md2py(md)\n",
    "    page_source = etree.HTML(str(toc.source))\n",
    "    papers = page_source.xpath(\"//li/a/text()\")\n",
    "    links = page_source.xpath(\"//li/a/@href\")\n",
    "    \n",
    "    ## the amoebanet modules may have strange paper name which is \"arXiv:1802.01548\". But the paper name can be got manually. \n",
    "    ## lets' omit this detail first. \n",
    "    ## if necessary, make some change. \n",
    "#     if \"amoebanet\" in module:\n",
    "#         pass        \n",
    "    \n",
    "    papers = list(map(beautify_string, papers))\n",
    "    papers = remove_github_items(\"GitHub issue\", papers)\n",
    "    links = remove_github_items(\"https://github.com\", links)\n",
    "\n",
    "    for paper, link in zip(papers, links):\n",
    "        paper_link[paper] = link\n",
    "\n",
    "        if paper not in paper_module:\n",
    "            paper_module[paper] = [module]\n",
    "        else:\n",
    "            if module not in paper_module[paper]:\n",
    "                paper_module[paper].append(module)\n",
    "#             if module not in module_paper:\n",
    "#                 module_paper[module] = [paper]\n",
    "#             else:\n",
    "#                 if paper not in module_paper[module]:\n",
    "#                     module_paper[module].append(paper)    \n",
    "    module_paper[module] = papers\n",
    "    \n",
    "def add_paper_into_dicts(paper, module):\n",
    "    if paper not in paper_module:\n",
    "        paper_module[paper] = [module]\n",
    "    else:\n",
    "        if module not in paper_module[paper]:\n",
    "            paper_module[paper].append(module)\n",
    "\n",
    "def getting_information():\n",
    "    with open(JSON_FILE, \"r\") as jf:\n",
    "        items = json.load(jf)\n",
    "    for item in items:\n",
    "        module = item[\"name\"]\n",
    "        version = item[\"version\"]\n",
    "        info = item[\"info\"]\n",
    "        link_url = \"https://aihub.cloud.google.com/p/products%2F{}\".format(info[1][1].split(\"/\")[1])\n",
    "        md = info[1][7]\n",
    "\n",
    "        if module in module_version:\n",
    "            module_version[module].append(version)\n",
    "        else:\n",
    "            module_version[module] = [version]\n",
    "\n",
    "        module_link[module] = link_url\n",
    "\n",
    "        if \"imagenet\" in module.split(\"-\")[0]:    \n",
    "            get_reference_info(module, md)\n",
    "        elif \"eference\" in md:\n",
    "            toc = md2py.md2py(md)\n",
    "            page_source = etree.HTML(str(toc.source))\n",
    "            ## paper name could be in the following two xpathes.\n",
    "    #         combi1 = page_source.xpath(\"//p[last()]/text()\")\n",
    "    #         print(combi1)\n",
    "            combi2 = page_source.xpath(\"//a[last()]/text()\")\n",
    "            ## the best part is in \"paper\"\n",
    "            if \"universal-sentence-encoder-xling\" in module:\n",
    "                paper1 = \"Learning Cross-Lingual Sentence Representations via a Multi-task Dual-Encoder Model.\" ## combi1 will be: ['[1] M. Chidambaram, Y. Yang, D. Cer, S. Yuan, Y.-H. Sung, B. Strope, and R.\\nKurzweil. Learning Cross-Lingual Sentence Representations via a Multi-task\\nDual-Encoder Model. ArXiv e-prints, October 2018.']\n",
    "                add_paper_into_dicts(paper1, module)\n",
    "                paper2 = \"Universal Sentence Encoder\"\n",
    "                add_paper_into_dicts(paper2, module)\n",
    "                module_paper[module] = [paper1, paper2]\n",
    "            elif \"delf\" in module:\n",
    "                papers = list(map(beautify_string, combi2))\n",
    "                for paper in papers:\n",
    "                    add_paper_into_dicts(paper, module)\n",
    "                module_paper[module] = papers\n",
    "            else:\n",
    "                paper = combi2[-1].replace(\"\\n\", \"\")\n",
    "                add_paper_into_dicts(paper, module)\n",
    "                module_paper[module] = [paper]\n",
    "        else:\n",
    "            if \"tf2-preview\" in module:\n",
    "                get_reference_info(module, md)\n",
    "            elif \"inaturalist-inception_v3\" in module:\n",
    "                get_reference_info(module, md)\n",
    "            else:\n",
    "                print(module, version, link_url)\n",
    "                pass\n",
    "\n",
    "getting_information()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_paper_and_module(papers, modules):\n",
    "    for paper in papers:\n",
    "        paper_module[paper] = modules\n",
    "    for module in modules:\n",
    "        module_paper[module] = papers\n",
    "add_paper_and_module(\n",
    "    [\"AutoAugment: Learning Augmentation Policies from Data\"], \n",
    "    [\n",
    "        \"image_augmentation-nas_svhn\", \n",
    "        \"image_augmentation-nas_imagenet\", \n",
    "        \"image_augmentation-nas_cifar\"\n",
    "    ]\n",
    ")\n",
    "paper_link[\"AutoAugment: Learning Augmentation Policies from Data\"] = \"https://arxiv.org/abs/1805.09501\"\n",
    "module_link[\"image_augmentation-nas_svhn\"] = \"https://aihub.cloud.google.com/p/products%2F5eef4456-8aa9-47d7-84db-00a7faa6662a\"\n",
    "module_link[\"image_augmentation-nas_imagenet\"] = \"https://aihub.cloud.google.com/p/products%2Fdaf153b0-cc1b-4f27-a037-5bd3d9fff224\"\n",
    "module_link[\"image_augmentation-nas_cifar\"] = \"https://aihub.cloud.google.com/p/products%2F822fa7f1-2207-4645-bcab-b7b916dae368\"\n",
    "\n",
    "\n",
    "\n",
    "# paper_module[\"AutoAugment: Learning Augmentation Policies from Data\"] = [\n",
    "#     \"image_augmentation-nas_svhn\", \n",
    "#     \"image_augmentation-nas_imagenet\", \n",
    "#     \"image_augmentation-nas_cifar\"\n",
    "# ]\n",
    "# module_paper[\"image_augmentation-nas_svhn\"] = [\"AutoAugment: Learning Augmentation Policies from Data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paper_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noted that: imagenet-amoebanet_a_n18_f448-classification and imagenet-amoebanet_a_n18_f448-feature_vector have 2 references: regularized evolution for image classifier architecture search & learning transferable architectures for scalable image recognition.\n",
    "\n",
    "According to our implementation, the paper \"regularized ...\" will shown as \"arXiv:1802.01548\". That't not very important. We can always make the change manually. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def find_value_in_dict(key, dic):\n",
    "    try: \n",
    "        return dic[key]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def print_list_of_dict(ds, link1, link2, fileName = \"heheda.md\"):\n",
    "    ls = list(ds.keys())\n",
    "    ls.sort()\n",
    "    with open(fileName, \"w\") as fw:\n",
    "        counter = 0\n",
    "        for l in ls:\n",
    "            counter += 1\n",
    "            fw.write(f\"## {counter}. {l}\\n\")\n",
    "            fw.write(f\"* link: {find_value_in_dict(l, link1)}\\n\")\n",
    "            ds[l].sort()\n",
    "            fw.write(\"* items: \\n\")\n",
    "\n",
    "            for m in ds[l]:\n",
    "                fw.write(\"    * {} {}\\n\".format(m, find_value_in_dict(m, link2)))\n",
    "            fw.write(\"\\n\")\n",
    "\n",
    "print_list_of_dict(paper_module, paper_link, module_link, \"paper_module_list.md\")\n",
    "print_list_of_dict(module_paper, module_link, paper_link, \"module_paper_list.md\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def print_paper_module(ds, link1, link2, fileName = \"heheda.md\"):\n",
    "    ls = list(ds.keys())\n",
    "    ls.sort()\n",
    "    with open(fileName, \"w\") as fw:\n",
    "        counter = 0\n",
    "        for l in ls:\n",
    "            counter += 1\n",
    "            fw.write(f\"## {counter}. {l}\\n\")\n",
    "            fw.write(f\"* link: {find_value_in_dict(l, link1)}\\n\")\n",
    "            ds[l].sort()\n",
    "            fw.write(\"* modules: \\n\")\n",
    "\n",
    "            for m in ds[l]:\n",
    "                fw.write(f\"    * {m}\\n\")\n",
    "                fw.write(\"        * versions: {}\\n\".format(len(module_version[m])))\n",
    "                fw.write(\"        * link: {}\\n\".format(find_value_in_dict(m, link2)))\n",
    "                \n",
    "            fw.write(\"\\n\")\n",
    "print_paper_module(paper_module, paper_link, module_link, \"paper_module_list.md\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def print_module_paper(ds, link1, link2, fileName = \"heheda.md\"):\n",
    "    ls = list(ds.keys())\n",
    "    ls.sort()\n",
    "    with open(fileName, \"w\") as fw:\n",
    "        counter = 0\n",
    "        for l in ls:\n",
    "            counter += 1\n",
    "            fw.write(f\"## {counter}. {l}\\n\")\n",
    "            fw.write(f\"* link: {find_value_in_dict(l, link1)}\\n\")\n",
    "            fw.write(f\"* versions: {len(module_version[l])}\\n\")\n",
    "            ds[l].sort()\n",
    "            fw.write(\"* papers: \\n\")\n",
    "\n",
    "            for m in ds[l]:\n",
    "                fw.write(f\"    * {m} __link:__ {find_value_in_dict(m, link2)}\\n\")\n",
    "#                 fw.write(\"        * link: {}\\n\".format(find_value_in_dict(m, link2)))\n",
    "                \n",
    "            fw.write(\"\\n\")\n",
    "print_module_paper(module_paper, module_link, paper_link, \"module_paper_list.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(module_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Wiki-words-250': ['Efficient Estimation of Word Representations in Vector '\n",
      "                    'Space'],\n",
      " 'Wiki-words-250-with-normalization': ['Efficient Estimation of Word '\n",
      "                                       'Representations in Vector Space'],\n",
      " 'Wiki-words-500': ['Efficient Estimation of Word Representations in Vector '\n",
      "                    'Space'],\n",
      " 'Wiki-words-500-with-normalization': ['Efficient Estimation of Word '\n",
      "                                       'Representations in Vector Space'],\n",
      " 'bert_cased_L-12_H-768_A-12': ['BERT:Pre-training of Deep Bidirectional '\n",
      "                                'Transformers for LanguageUnderstanding'],\n",
      " 'bert_cased_L-24_H-1024_A-16': ['BERT:Pre-training of Deep Bidirectional '\n",
      "                                 'Transformers for LanguageUnderstanding'],\n",
      " 'bert_chinese_L-12_H-768_A-12': ['BERT:Pre-training of Deep Bidirectional '\n",
      "                                  'Transformers for LanguageUnderstanding'],\n",
      " 'bert_multi_cased_L-12_H-768_A-12': ['BERT:Pre-training of Deep Bidirectional '\n",
      "                                      'Transformers for LanguageUnderstanding'],\n",
      " 'bert_uncased_L-12_H-768_A-12': ['BERT:Pre-training of Deep Bidirectional '\n",
      "                                  'Transformers for LanguageUnderstanding'],\n",
      " 'bert_uncased_L-24_H-1024_A-16': ['BERT:Pre-training of Deep Bidirectional '\n",
      "                                   'Transformers for LanguageUnderstanding'],\n",
      " 'biggan-128': ['Large Scale GAN Training for High Fidelity Natural Image '\n",
      "                'Synthesis'],\n",
      " 'biggan-256': ['Large Scale GAN Training for High Fidelity Natural Image '\n",
      "                'Synthesis'],\n",
      " 'biggan-512': ['Large Scale GAN Training for High Fidelity Natural Image '\n",
      "                'Synthesis'],\n",
      " 'biggan-deep-128': ['Large Scale GAN Training for High Fidelity Natural Image '\n",
      "                     'Synthesis'],\n",
      " 'biggan-deep-256': ['Large Scale GAN Training for High Fidelity Natural Image '\n",
      "                     'Synthesis'],\n",
      " 'biggan-deep-512': ['Large Scale GAN Training for High Fidelity Natural Image '\n",
      "                     'Synthesis'],\n",
      " 'compare_gan-model_10_lsun_bedroom_resnet19': ['The GAN Landscape: Losses, '\n",
      "                                                'Architectures, '\n",
      "                                                'Regularization, and '\n",
      "                                                'Normalization'],\n",
      " 'compare_gan-model_11_cifar10_resnet_cifar': ['The GAN Landscape: Losses, '\n",
      "                                               'Architectures, Regularization, '\n",
      "                                               'and Normalization'],\n",
      " 'compare_gan-model_12_cifar10_resnet_cifar': ['The GAN Landscape: Losses, '\n",
      "                                               'Architectures, Regularization, '\n",
      "                                               'and Normalization'],\n",
      " 'compare_gan-model_13_cifar10_resnet_cifar': ['The GAN Landscape: Losses, '\n",
      "                                               'Architectures, Regularization, '\n",
      "                                               'and Normalization'],\n",
      " 'compare_gan-model_14_cifar10_resnet_cifar': ['The GAN Landscape: Losses, '\n",
      "                                               'Architectures, Regularization, '\n",
      "                                               'and Normalization'],\n",
      " 'compare_gan-model_15_cifar10_resnet_cifar': ['The GAN Landscape: Losses, '\n",
      "                                               'Architectures, Regularization, '\n",
      "                                               'and Normalization'],\n",
      " 'compare_gan-model_1_celebahq128_resnet19': ['The GAN Landscape: Losses, '\n",
      "                                              'Architectures, Regularization, '\n",
      "                                              'and Normalization'],\n",
      " 'compare_gan-model_2_celebahq128_resnet19': ['The GAN Landscape: Losses, '\n",
      "                                              'Architectures, Regularization, '\n",
      "                                              'and Normalization'],\n",
      " 'compare_gan-model_3_lsun_bedroom_resnet19': ['The GAN Landscape: Losses, '\n",
      "                                               'Architectures, Regularization, '\n",
      "                                               'and Normalization'],\n",
      " 'compare_gan-model_4_lsun_bedroom_resnet19': ['The GAN Landscape: Losses, '\n",
      "                                               'Architectures, Regularization, '\n",
      "                                               'and Normalization'],\n",
      " 'compare_gan-model_5_celebahq128_resnet19': ['The GAN Landscape: Losses, '\n",
      "                                              'Architectures, Regularization, '\n",
      "                                              'and Normalization'],\n",
      " 'compare_gan-model_6_celebahq128_resnet19': ['The GAN Landscape: Losses, '\n",
      "                                              'Architectures, Regularization, '\n",
      "                                              'and Normalization'],\n",
      " 'compare_gan-model_7_lsun_bedroom_resnet19': ['The GAN Landscape: Losses, '\n",
      "                                               'Architectures, Regularization, '\n",
      "                                               'and Normalization'],\n",
      " 'compare_gan-model_8_lsun_bedroom_resnet19': ['The GAN Landscape: Losses, '\n",
      "                                               'Architectures, Regularization, '\n",
      "                                               'and Normalization'],\n",
      " 'compare_gan-model_9_celebahq128_resnet19': ['The GAN Landscape: Losses, '\n",
      "                                              'Architectures, Regularization, '\n",
      "                                              'and Normalization'],\n",
      " 'compare_gan-s3gan_20_128x128': ['High-Fidelity Image Generation With Fewer '\n",
      "                                  'Labels'],\n",
      " 'compare_gan-s3gan_2_5_128x128': ['High-Fidelity Image Generation With Fewer '\n",
      "                                   'Labels'],\n",
      " 'compare_gan-s3gan_5_128x128': ['High-Fidelity Image Generation With Fewer '\n",
      "                                 'Labels'],\n",
      " 'delf': ['Deep Image Retrieval: Learning global representations for image '\n",
      "          'search',\n",
      "          'Large-Scale Image Retrieval with Attentive Deep Local Features'],\n",
      " 'elmo': ['Deep contextualized word representations'],\n",
      " 'i3d-kinetics-400': ['Quo Vadis, Action Recognition? A New Model and the '\n",
      "                      'Kinetics Dataset'],\n",
      " 'i3d-kinetics-600': ['Quo Vadis, Action Recognition? A New Model and the '\n",
      "                      'Kinetics Dataset'],\n",
      " 'image_augmentation-nas_cifar': ['AutoAugment: Learning Augmentation Policies '\n",
      "                                  'from Data'],\n",
      " 'image_augmentation-nas_imagenet': ['AutoAugment: Learning Augmentation '\n",
      "                                     'Policies from Data'],\n",
      " 'image_augmentation-nas_svhn': ['AutoAugment: Learning Augmentation Policies '\n",
      "                                 'from Data'],\n",
      " 'imagenet-amoebanet_a_n18_f448-classification': ['Learning Transferable '\n",
      "                                                  'Architectures for Scalable '\n",
      "                                                  'Image Recognition',\n",
      "                                                  'arXiv:1802.01548'],\n",
      " 'imagenet-amoebanet_a_n18_f448-feature_vector': ['Learning Transferable '\n",
      "                                                  'Architectures for Scalable '\n",
      "                                                  'Image Recognition',\n",
      "                                                  'arXiv:1802.01548'],\n",
      " 'imagenet-inception_resnet_v2-classification': ['Inception-v4, '\n",
      "                                                 'Inception-ResNet and the '\n",
      "                                                 'Impact of Residual '\n",
      "                                                 'Connections on Learning'],\n",
      " 'imagenet-inception_resnet_v2-feature_vector': ['Inception-v4, '\n",
      "                                                 'Inception-ResNet and the '\n",
      "                                                 'Impact of Residual '\n",
      "                                                 'Connections on Learning'],\n",
      " 'imagenet-inception_v1-classification': ['Going deeper with convolutions'],\n",
      " 'imagenet-inception_v1-feature_vector': ['Going deeper with convolutions'],\n",
      " 'imagenet-inception_v2-classification': ['Batch Normalization: Accelerating '\n",
      "                                          'Deep Network Training by Reducing '\n",
      "                                          'Internal Covariate Shift',\n",
      "                                          'Going deeper with convolutions'],\n",
      " 'imagenet-inception_v2-feature_vector': ['Batch Normalization: Accelerating '\n",
      "                                          'Deep Network Training by Reducing '\n",
      "                                          'Internal Covariate Shift',\n",
      "                                          'Going deeper with convolutions'],\n",
      " 'imagenet-inception_v3-classification': ['Rethinking the Inception '\n",
      "                                          'Architecture for Computer Vision'],\n",
      " 'imagenet-inception_v3-feature_vector': ['Rethinking the Inception '\n",
      "                                          'Architecture for Computer Vision'],\n",
      " 'imagenet-mobilenet_v1_025_128-classification': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_025_128-feature_vector': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_025_128-quantops-classification': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_025_128-quantops-feature_vector': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_025_160-classification': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_025_160-feature_vector': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_025_160-quantops-classification': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_025_160-quantops-feature_vector': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_025_192-classification': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_025_192-feature_vector': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_025_192-quantops-classification': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_025_192-quantops-feature_vector': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_025_224-classification': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_025_224-feature_vector': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_025_224-quantops-classification': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_025_224-quantops-feature_vector': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_050_128-classification': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_050_128-feature_vector': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_050_128-quantops-classification': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_050_128-quantops-feature_vector': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_050_160-classification': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_050_160-feature_vector': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_050_160-quantops-classification': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_050_160-quantops-feature_vector': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_050_192-classification': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_050_192-feature_vector': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_050_192-quantops-classification': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_050_192-quantops-feature_vector': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_050_224-classification': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_050_224-feature_vector': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_050_224-quantops-classification': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_050_224-quantops-feature_vector': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_075_128-classification': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_075_128-feature_vector': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_075_128-quantops-classification': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_075_128-quantops-feature_vector': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_075_160-classification': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_075_160-feature_vector': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_075_160-quantops-classification': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_075_160-quantops-feature_vector': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_075_192-classification': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_075_192-feature_vector': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_075_192-quantops-classification': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_075_192-quantops-feature_vector': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_075_224-classification': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_075_224-feature_vector': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_075_224-quantops-classification': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_075_224-quantops-feature_vector': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_100_128-classification': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_100_128-feature_vector': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_100_128-quantops-classification': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_100_128-quantops-feature_vector': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_100_160-classification': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_100_160-feature_vector': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_100_160-quantops-classification': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_100_160-quantops-feature_vector': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_100_192-classification': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_100_192-feature_vector': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_100_192-quantops-classification': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_100_192-quantops-feature_vector': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_100_224-classification': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_100_224-feature_vector': ['MobileNets: Efficient '\n",
      "                                                  'Convolutional Neural '\n",
      "                                                  'Networks for Mobile Vision '\n",
      "                                                  'Applications'],\n",
      " 'imagenet-mobilenet_v1_100_224-quantops-classification': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v1_100_224-quantops-feature_vector': ['MobileNets: '\n",
      "                                                           'Efficient '\n",
      "                                                           'Convolutional '\n",
      "                                                           'Neural Networks '\n",
      "                                                           'for Mobile Vision '\n",
      "                                                           'Applications'],\n",
      " 'imagenet-mobilenet_v2_035_128-classification': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_035_128-feature_vector': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_035_160-classification': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_035_160-feature_vector': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_035_192-classification': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_035_192-feature_vector': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_035_224-classification': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_035_224-feature_vector': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_035_96-classification': ['Inverted Residuals and '\n",
      "                                                 'Linear Bottlenecks: Mobile '\n",
      "                                                 'Networks for Classification, '\n",
      "                                                 'Detection and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_035_96-feature_vector': ['Inverted Residuals and '\n",
      "                                                 'Linear Bottlenecks: Mobile '\n",
      "                                                 'Networks for Classification, '\n",
      "                                                 'Detection and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_050_128-classification': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_050_128-feature_vector': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_050_160-classification': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_050_160-feature_vector': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_050_192-classification': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_050_192-feature_vector': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_050_224-classification': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_050_224-feature_vector': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_050_96-classification': ['Inverted Residuals and '\n",
      "                                                 'Linear Bottlenecks: Mobile '\n",
      "                                                 'Networks for Classification, '\n",
      "                                                 'Detection and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_050_96-feature_vector': ['Inverted Residuals and '\n",
      "                                                 'Linear Bottlenecks: Mobile '\n",
      "                                                 'Networks for Classification, '\n",
      "                                                 'Detection and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_075_128-classification': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_075_128-feature_vector': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_075_160-classification': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_075_160-feature_vector': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_075_192-classification': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_075_192-feature_vector': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_075_224-classification': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_075_224-feature_vector': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_075_96-classification': ['Inverted Residuals and '\n",
      "                                                 'Linear Bottlenecks: Mobile '\n",
      "                                                 'Networks for Classification, '\n",
      "                                                 'Detection and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_075_96-feature_vector': ['Inverted Residuals and '\n",
      "                                                 'Linear Bottlenecks: Mobile '\n",
      "                                                 'Networks for Classification, '\n",
      "                                                 'Detection and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_100_128-classification': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_100_128-feature_vector': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_100_160-classification': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_100_160-feature_vector': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_100_192-classification': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_100_192-feature_vector': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_100_224-classification': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_100_224-feature_vector': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_100_96-classification': ['Inverted Residuals and '\n",
      "                                                 'Linear Bottlenecks: Mobile '\n",
      "                                                 'Networks for Classification, '\n",
      "                                                 'Detection and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_100_96-feature_vector': ['Inverted Residuals and '\n",
      "                                                 'Linear Bottlenecks: Mobile '\n",
      "                                                 'Networks for Classification, '\n",
      "                                                 'Detection and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_130_224-classification': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_130_224-feature_vector': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_140_224-classification': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-mobilenet_v2_140_224-feature_vector': ['Inverted Residuals and '\n",
      "                                                  'Linear Bottlenecks: Mobile '\n",
      "                                                  'Networks for '\n",
      "                                                  'Classification, Detection '\n",
      "                                                  'and Segmentation'],\n",
      " 'imagenet-nasnet_large-classification': ['Learning Transferable Architectures '\n",
      "                                          'for Scalable Image Recognition',\n",
      "                                          'Neural Architecture Search with '\n",
      "                                          'Reinforcement Learning'],\n",
      " 'imagenet-nasnet_large-feature_vector': ['Learning Transferable Architectures '\n",
      "                                          'for Scalable Image Recognition',\n",
      "                                          'Neural Architecture Search with '\n",
      "                                          'Reinforcement Learning'],\n",
      " 'imagenet-nasnet_mobile-classification': ['Learning Transferable '\n",
      "                                           'Architectures for Scalable Image '\n",
      "                                           'Recognition',\n",
      "                                           'Neural Architecture Search with '\n",
      "                                           'Reinforcement Learning'],\n",
      " 'imagenet-nasnet_mobile-feature_vector': ['Learning Transferable '\n",
      "                                           'Architectures for Scalable Image '\n",
      "                                           'Recognition',\n",
      "                                           'Neural Architecture Search with '\n",
      "                                           'Reinforcement Learning'],\n",
      " 'imagenet-pnasnet_large-classification': ['Learning Transferable '\n",
      "                                           'Architectures for Scalable Image '\n",
      "                                           'Recognition',\n",
      "                                           'Progressive Neural Architecture '\n",
      "                                           'Search'],\n",
      " 'imagenet-pnasnet_large-feature_vector': ['Learning Transferable '\n",
      "                                           'Architectures for Scalable Image '\n",
      "                                           'Recognition',\n",
      "                                           'Progressive Neural Architecture '\n",
      "                                           'Search'],\n",
      " 'imagenet-resnet_v1_101-classification': ['Deep Residual Learning for Image '\n",
      "                                           'Recognition'],\n",
      " 'imagenet-resnet_v1_101-feature_vector': ['Deep Residual Learning for Image '\n",
      "                                           'Recognition'],\n",
      " 'imagenet-resnet_v1_152-classification': ['Deep Residual Learning for Image '\n",
      "                                           'Recognition'],\n",
      " 'imagenet-resnet_v1_152-feature_vector': ['Deep Residual Learning for Image '\n",
      "                                           'Recognition'],\n",
      " 'imagenet-resnet_v1_50-classification': ['Deep Residual Learning for Image '\n",
      "                                          'Recognition'],\n",
      " 'imagenet-resnet_v1_50-feature_vector': ['Deep Residual Learning for Image '\n",
      "                                          'Recognition'],\n",
      " 'imagenet-resnet_v2_101-classification': ['Deep Residual Learning for Image '\n",
      "                                           'Recognition',\n",
      "                                           'Identity Mappings in Deep Residual '\n",
      "                                           'Networks'],\n",
      " 'imagenet-resnet_v2_101-feature_vector': ['Deep Residual Learning for Image '\n",
      "                                           'Recognition',\n",
      "                                           'Identity Mappings in Deep Residual '\n",
      "                                           'Networks'],\n",
      " 'imagenet-resnet_v2_152-classification': ['Deep Residual Learning for Image '\n",
      "                                           'Recognition',\n",
      "                                           'Identity Mappings in Deep Residual '\n",
      "                                           'Networks'],\n",
      " 'imagenet-resnet_v2_152-feature_vector': ['Deep Residual Learning for Image '\n",
      "                                           'Recognition',\n",
      "                                           'Identity Mappings in Deep Residual '\n",
      "                                           'Networks'],\n",
      " 'imagenet-resnet_v2_50-classification': ['Deep Residual Learning for Image '\n",
      "                                          'Recognition',\n",
      "                                          'Identity Mappings in Deep Residual '\n",
      "                                          'Networks'],\n",
      " 'imagenet-resnet_v2_50-feature_vector': ['Deep Residual Learning for Image '\n",
      "                                          'Recognition',\n",
      "                                          'Identity Mappings in Deep Residual '\n",
      "                                          'Networks'],\n",
      " 'inaturalist-inception_v3-feature_vector': ['Large Scale Fine-Grained '\n",
      "                                             'Categorization and '\n",
      "                                             'Domain-Specific Transfer '\n",
      "                                             'Learning',\n",
      "                                             'Rethinking the Inception '\n",
      "                                             'Architecture for Computer Vision',\n",
      "                                             'The iNaturalist Species '\n",
      "                                             'Classification and Detection '\n",
      "                                             'Dataset'],\n",
      " 'nnlm-de-dim128': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-de-dim128-with-normalization': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-de-dim50': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-de-dim50-with-normalization': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-en-dim128': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-en-dim128-with-normalization': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-en-dim50': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-en-dim50-with-normalization': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-es-dim128': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-es-dim128-with-normalization': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-es-dim50': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-es-dim50-with-normalization': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-id-dim128': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-id-dim128-with-normalization': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-id-dim50': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-id-dim50-with-normalization': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-ja-dim128': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-ja-dim128-with-normalization': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-ja-dim50': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-ja-dim50-with-normalization': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-ko-dim128': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-ko-dim128-with-normalization': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-ko-dim50': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-ko-dim50-with-normalization': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-zh-dim128': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-zh-dim128-with-normalization': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-zh-dim50': ['A Neural Probabilistic Language Model'],\n",
      " 'nnlm-zh-dim50-with-normalization': ['A Neural Probabilistic Language Model'],\n",
      " 'progan-128': ['Progressive Growing of GANs for Improved Quality, Stability, '\n",
      "                'and Variation'],\n",
      " 'tf2-preview-gnews-swivel-20dim': ['Swivel: Improving Embeddings by Noticing '\n",
      "                                    \"What's Missing\"],\n",
      " 'tf2-preview-gnews-swivel-20dim-with-oov': ['Swivel: Improving Embeddings by '\n",
      "                                             \"Noticing What's Missing\"],\n",
      " 'tf2-preview-inception_v3-classification': ['Rethinking the Inception '\n",
      "                                             'Architecture for Computer '\n",
      "                                             'Vision'],\n",
      " 'tf2-preview-inception_v3-feature_vector': ['Rethinking the Inception '\n",
      "                                             'Architecture for Computer '\n",
      "                                             'Vision'],\n",
      " 'tf2-preview-mobilenet_v2-classification': ['Inverted Residuals and Linear '\n",
      "                                             'Bottlenecks: Mobile Networks for '\n",
      "                                             'Classification, Detection and '\n",
      "                                             'Segmentation'],\n",
      " 'tf2-preview-mobilenet_v2-feature_vector': ['Inverted Residuals and Linear '\n",
      "                                             'Bottlenecks: Mobile Networks for '\n",
      "                                             'Classification, Detection and '\n",
      "                                             'Segmentation'],\n",
      " 'tf2-preview-nnlm-en-dim128': ['A Neural Probabilistic Language Model'],\n",
      " 'tf2-preview-nnlm-en-dim50': ['A Neural Probabilistic Language Model'],\n",
      " 'universal-sentence-encoder': ['Universal Sentence Encoder'],\n",
      " 'universal-sentence-encoder-large': ['Universal Sentence Encoder'],\n",
      " 'universal-sentence-encoder-lite': ['Universal Sentence Encoder'],\n",
      " 'universal-sentence-encoder-xling-en-de': ['Learning Cross-Lingual Sentence '\n",
      "                                            'Representations via a Multi-task '\n",
      "                                            'Dual-Encoder Model.',\n",
      "                                            'Universal Sentence Encoder'],\n",
      " 'universal-sentence-encoder-xling-en-es': ['Learning Cross-Lingual Sentence '\n",
      "                                            'Representations via a Multi-task '\n",
      "                                            'Dual-Encoder Model.',\n",
      "                                            'Universal Sentence Encoder'],\n",
      " 'universal-sentence-encoder-xling-en-fr': ['Learning Cross-Lingual Sentence '\n",
      "                                            'Representations via a Multi-task '\n",
      "                                            'Dual-Encoder Model.',\n",
      "                                            'Universal Sentence Encoder'],\n",
      " 'universal-sentence-encoder-xling-many': ['Learning Cross-Lingual Sentence '\n",
      "                                           'Representations via a Multi-task '\n",
      "                                           'Dual-Encoder Model.',\n",
      "                                           'Universal Sentence Encoder']}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(module_paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 modules are not in there: \n",
    "\n",
    "#### 3 models don't have any reference info: \n",
    "\n",
    "(They don't clarify their references. Though their webpages look like the previous three, but I don't regard so for certain. )\n",
    "\n",
    "image_augmentation-crop_rotate_color 1 https://aihub.cloud.google.com/p/products%2Fcd9eda73-8cc4-4dbc-aa62-c97e98d657af\n",
    "\n",
    "image_augmentation-crop_color 1 https://aihub.cloud.google.com/p/products%2F83bb37d7-5060-4ba7-85e4-6c00a582e789\n",
    "\n",
    "image_augmentation-flipx_crop_rotate_color 1 https://aihub.cloud.google.com/p/products%2F2012b39c-9bd7-4670-bbc0-190c89405778\n",
    "\n",
    "#### 2 models clarify their referred stuff: \n",
    "faster_rcnn-openimages_v4-inception_resnet_v2 1 https://aihub.cloud.google.com/p/products%2F41b42dfa-e600-4a73-a425-7c5c4d511c3c\n",
    "* Only has some referred models and datasets: *FasterRCNN+InceptionResNetV2 network trained on Open Images V4*\n",
    "\n",
    "openimages_v4-ssd-mobilenet_v2 1 https://aihub.cloud.google.com/p/products%2F8c6878ba-d32d-411d-bac2-2f884b748c4f\n",
    "* Only has some referred models and datasets: *SSD+MobileNetV2 network trained on Open Images V4*\n",
    "\n",
    "#### 3 models don't have any reference info: \n",
    "\n",
    "ganeval-cifar10-convnet 1 https://aihub.cloud.google.com/p/products%2F110689d8-c594-49d6-aef4-9fc91c9c2ab4\n",
    "\n",
    "random-nnlm-en-dim50 1 https://aihub.cloud.google.com/p/products%2Fb0766fd5-82b5-48e3-9d6f-26c5d2601d5f\n",
    "\n",
    "random-nnlm-en-dim128 1 https://aihub.cloud.google.com/p/products%2Fa52e9466-f691-4f91-a62e-f6e39eb967f8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
