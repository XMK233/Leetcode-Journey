## 1. Wiki-words

**Text embedding based on skipgram version of word2vec with 1 out-of-vocabulary bucket. Maps from text to x-dimensional embedding vectors**

### 1.1 [Wiki-words-250@1](https://aihub.cloud.google.com/p/products%2F12ce75a1-5f7c-4452-997c-73b9998373ad)


Module Description: 

* output shape is 250 dimensions

*  The module preprocesses its input by splitting on spaces


References: 

* *Efficient Estimation of Word Representations in Vector Space*


Changelog: 

    None

### 1.2 [Wiki-words-250-with-normalization@1](https://aihub.cloud.google.com/p/products%2Fda0a53b5-a301-4641-b41d-d8aec0db9753)


Module Description: 

* output shape is 250 dimensions

*  The module preprocesses its input by removing punctuation and splitting on spaces


References: 

* *Efficient Estimation of Word Representations in Vector Space*


Changelog: 

    None

### 1.3 [Wiki-words-500@1](https://aihub.cloud.google.com/p/products%2Ffdbabad5-758b-46c7-a841-08386afa204f)


Module Description: 

* output shape is 500 dimensions

*  The module preprocesses its input by splitting on spaces


References: 

* *Efficient Estimation of Word Representations in Vector Space*


Changelog: 

    None

### 1.4 [Wiki-words-500-with-normalization@1](https://aihub.cloud.google.com/p/products%2Fae958f02-81f5-43ce-acfe-469b1fb18517)


Module Description: 

* output shape is 500 dimensions

*  The module preprocesses its input by removing punctuation and splitting on spaces


References: 

* *Efficient Estimation of Word Representations in Vector Space*


Changelog: 

    None

## 2. nnlm

**Text embedding based on feed-forward Neural-Net Language Models with pre-built OOV**

### 2.1 [nnlm-de-dim128@1](https://aihub.cloud.google.com/p/products%2F581bb5fd-cc8f-4adf-bc47-6b2fba56ed82)


Module Description: 

* Language: de

*  Map from text to 128-dimensional vectors

*  Based on NNLM with three hidden layers

*  Input preprocessed by splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.2 [nnlm-de-dim128-with-normalization@1](https://aihub.cloud.google.com/p/products%2F0d2e953e-7f38-4265-9e93-2095b2dd1c5c)


Module Description: 

* Language: de

*  Map from text to 128-dimensional vectors

*  Based on NNLM with three hidden layers

*  Input preprocessed by removing punctuation and splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.3 [nnlm-de-dim50@1](https://aihub.cloud.google.com/p/products%2F79ccd5a6-b604-448f-a71c-ea818a7ebc44)


Module Description: 

* Language: de

*  Map from text to 50-dimensional vectors

*  Based on NNLM with two hidden layers

*  Input preprocessed by splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.4 [nnlm-de-dim50-with-normalization@1](https://aihub.cloud.google.com/p/products%2F4bc8df1d-c51e-4727-8c00-c728f8bb28ee)


Module Description: 

* Language: de

*  Map from text to 50-dimensional vectors

*  Based on NNLM with two hidden layers

*  Input preprocessed by removing punctuation and splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.5 [nnlm-en-dim128@1](https://aihub.cloud.google.com/p/products%2Fa3184819-f94d-402c-9b0e-854b10d03db9)


Module Description: 

* Language: en

*  Map from text to 128-dimensional vectors

*  Based on NNLM with three hidden layers

*  Input preprocessed by splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.6 [nnlm-en-dim128-with-normalization@1](https://aihub.cloud.google.com/p/products%2Fd62c150f-ba94-4a0e-af48-028f0740c766)


Module Description: 

* Language: en

*  Map from text to 128-dimensional vectors

*  Based on NNLM with three hidden layers

*  Input preprocessed by removing punctuation and splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.7 [nnlm-en-dim50@1](https://aihub.cloud.google.com/p/products%2Feb4cd7ec-6549-4b4d-bb00-eaa1de9fa3cb)


Module Description: 

* Language: en

*  Map from text to 50-dimensional vectors

*  Based on NNLM with two hidden layers

*  Input preprocessed by splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.8 [nnlm-en-dim50-with-normalization@1](https://aihub.cloud.google.com/p/products%2Fd0b6d1fb-7152-43b6-b8bc-f1776be3211b)


Module Description: 

* Language: en

*  Map from text to 50-dimensional vectors

*  Based on NNLM with two hidden layers

*  Input preprocessed by removing punctuation and splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.9 [nnlm-es-dim128@1](https://aihub.cloud.google.com/p/products%2Ff6a82be2-a31e-4630-b022-d746518a83ba)


Module Description: 

* Language: es

*  Map from text to 128-dimensional vectors

*  Based on NNLM with three hidden layers

*  Input preprocessed by splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.10 [nnlm-es-dim128-with-normalization@1](https://aihub.cloud.google.com/p/products%2Fad884d6a-a003-4a85-8653-76bdaff093f2)


Module Description: 

* Language: es

*  Map from text to 128-dimensional vectors

*  Based on NNLM with three hidden layers

*  Input preprocessed by removing punctuation and splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.11 [nnlm-es-dim50@1](https://aihub.cloud.google.com/p/products%2Ff7bf57ae-39e2-415e-b6c4-7066e03d0fd4)


Module Description: 

* Language: es

*  Map from text to 50-dimensional vectors

*  Based on NNLM with two hidden layers

*  Input preprocessed by splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.12 [nnlm-es-dim50-with-normalization@1](https://aihub.cloud.google.com/p/products%2F21cbb434-e8f4-4155-8084-7530b7b17fea)


Module Description: 

* Language: es

*  Map from text to 50-dimensional vectors

*  Based on NNLM with two hidden layers

*  Input preprocessed by removing punctuation and splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.13 [nnlm-id-dim128@1](https://aihub.cloud.google.com/p/products%2F3e58488d-9270-4884-ba92-aecb57373ec1)


Module Description: 

* Language: id

*  Map from text to 128-dimensional vectors

*  Based on NNLM with three hidden layers

*  Input preprocessed by splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.14 [nnlm-id-dim128-with-normalization@1](https://aihub.cloud.google.com/p/products%2F4b795742-90ab-4942-8907-dbe98884e9db)


Module Description: 

* Language: id

*  Map from text to 128-dimensional vectors

*  Based on NNLM with three hidden layers

*  Input preprocessed by removing punctuation and splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.15 [nnlm-id-dim50@1](https://aihub.cloud.google.com/p/products%2F09702e46-753b-4dad-80bf-d0dda1b0421f)


Module Description: 

* Language: id

*  Map from text to 50-dimensional vectors

*  Based on NNLM with two hidden layers

*  Input preprocessed by splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.16 [nnlm-id-dim50-with-normalization@1](https://aihub.cloud.google.com/p/products%2F0a8e3c49-c4f4-4c85-a8ff-307b6e6708bf)


Module Description: 

* Language: id

*  Map from text to 50-dimensional vectors

*  Based on NNLM with two hidden layers

*  Input preprocessed by removing punctuation and splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.17 [nnlm-ja-dim128@1](https://aihub.cloud.google.com/p/products%2Fd22a0516-404f-4737-83fa-eefaaa6952e5)


Module Description: 

* Language: ja

*  Map from text to 128-dimensional vectors

*  Based on NNLM with three hidden layers

*  Input preprocessed by splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.18 [nnlm-ja-dim128-with-normalization@1](https://aihub.cloud.google.com/p/products%2F66533fdb-a87d-4415-ad5a-d72aab38269f)


Module Description: 

* Language: ja

*  Map from text to 128-dimensional vectors

*  Based on NNLM with three hidden layers

*  Input preprocessed by removing punctuation and splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.19 [nnlm-ja-dim50@1](https://aihub.cloud.google.com/p/products%2F187a1ce7-a131-4eda-b26f-e01eee47246e)


Module Description: 

* Language: ja

*  Map from text to 50-dimensional vectors

*  Based on NNLM with two hidden layers

*  Input preprocessed by splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.20 [nnlm-ja-dim50-with-normalization@1](https://aihub.cloud.google.com/p/products%2F75f7408b-31e7-49e2-958b-50e380e2b21a)


Module Description: 

* Language: ja

*  Map from text to 50-dimensional vectors

*  Based on NNLM with two hidden layers

*  Input preprocessed by removing punctuation and splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.21 [nnlm-ko-dim128@1](https://aihub.cloud.google.com/p/products%2Ffd04f17e-9939-41c0-a2b7-7789878f7b7d)


Module Description: 

* Language: ko

*  Map from text to 128-dimensional vectors

*  Based on NNLM with three hidden layers

*  Input preprocessed by splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.22 [nnlm-ko-dim128-with-normalization@1](https://aihub.cloud.google.com/p/products%2Ff405f842-d604-4b1c-b074-0d16a0ff225d)


Module Description: 

* Language: ko

*  Map from text to 128-dimensional vectors

*  Based on NNLM with three hidden layers

*  Input preprocessed by removing punctuation and splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.23 [nnlm-ko-dim50@1](https://aihub.cloud.google.com/p/products%2F33345f54-4152-4228-933a-03ffdc729c02)


Module Description: 

* Language: ko

*  Map from text to 50-dimensional vectors

*  Based on NNLM with two hidden layers

*  Input preprocessed by splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.24 [nnlm-ko-dim50-with-normalization@1](https://aihub.cloud.google.com/p/products%2F8dd3f7e0-98b7-4d1d-aff8-fdf98e8d0528)


Module Description: 

* Language: ko

*  Map from text to 50-dimensional vectors

*  Based on NNLM with two hidden layers

*  Input preprocessed by removing punctuation and splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.25 [nnlm-zh-dim128@1](https://aihub.cloud.google.com/p/products%2F5adc3e79-881d-4450-95ad-6a9af0df7f22)


Module Description: 

* Language: zh

*  Map from text to 128-dimensional vectors

*  Based on NNLM with three hidden layers

*  Input preprocessed by splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.26 [nnlm-zh-dim128-with-normalization@1](https://aihub.cloud.google.com/p/products%2Faf41efc4-c8aa-4b0c-a13c-39abcd2ddfd4)


Module Description: 

* Language: zh

*  Map from text to 128-dimensional vectors

*  Based on NNLM with three hidden layers

*  Input preprocessed by removing punctuation and splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.27 [nnlm-zh-dim50@1](https://aihub.cloud.google.com/p/products%2F3f91c2fb-6eb8-4539-96cf-2ab91ac39e3a)


Module Description: 

* Language: zh

*  Map from text to 50-dimensional vectors

*  Based on NNLM with two hidden layers

*  Input preprocessed by splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 2.28 [nnlm-zh-dim50-with-normalization@1](https://aihub.cloud.google.com/p/products%2F4c36797c-3d02-4332-8c8f-16f1d5c23347)


Module Description: 

* Language: zh

*  Map from text to 50-dimensional vectors

*  Based on NNLM with two hidden layers

*  Input preprocessed by removing punctuation and splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

## 3. random-nnlm

**Text embedding initialized with some random normal tensor; It contains no "knowledge", but can conveniently be used as a baseline when comparing to other modules; Vocabulary of the module is based on other nnlm modules in TFHub**

### 3.1 [random-nnlm-en-dim128@1](https://aihub.cloud.google.com/p/products%2Fa52e9466-f691-4f91-a62e-f6e39eb967f8)


Module Description: 

* Text embedding initialized with tf.random_normal([vocabulary_size, 128])

*  Vocabulary of the module is based on nnlm-en-dim128


References: 




Changelog: 

    None

### 3.2 [random-nnlm-en-dim50@1](https://aihub.cloud.google.com/p/products%2Fb0766fd5-82b5-48e3-9d6f-26c5d2601d5f)


Module Description: 

* Text embedding initialized with tf.random_normal([vocabulary_size, 50])

*  Vocabulary of the module is based on nnlm-en-dim50


References: 




Changelog: 

    None

## 4. tf2-preview-gnews-swivel

**SavedModel 2.0 format; help preview TensorFlow 2.0 functionality; Text embedding based on Swivel co-occurrence matrix factorization with pre-built OOV**

### 4.1 [tf2-preview-gnews-swivel-20dim@1](https://aihub.cloud.google.com/p/products%2F6b1c1b14-d974-44d8-a131-4c132be4b26d)


Module Description: 

* Map from text to 20-dimensional vectors

*  Created using Swivel matrix factorization method

*  Input preprocessed by splitting on spaces


References: 

* *Swivel: Improving Embeddings by Noticing What's Missing*


Changelog: 

    None

### 4.2 [tf2-preview-gnews-swivel-20dim-with-oov@1](https://aihub.cloud.google.com/p/products%2F18fdd467-ce81-48d8-aa41-058bccff5432)


Module Description: 

* Map from text to 20-dimensional vectors

*  Created using Swivel matrix factorization method

*  Input preprocessed by splitting on spaces


References: 

* *Swivel: Improving Embeddings by Noticing What's Missing*


Changelog: 

    None

## 5. tf2-preview-nnlm

**SavedModel 2.0 format; help preview TensorFlow 2.0 functionality; Text embedding based on feed-forward Neural-Net Language Models with pre-built OOV**

### 5.1 [tf2-preview-nnlm-en-dim128@1](https://aihub.cloud.google.com/p/products%2F89613833-f812-4e13-adb9-7e1078904f3e)


Module Description: 

* Language: en

*  Map from text to 128-dimensional vectors

*  Based on NNLM with three hidden layers

*  Input preprocessed by splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

### 5.2 [tf2-preview-nnlm-en-dim50@1](https://aihub.cloud.google.com/p/products%2Ff0382a1c-6527-4e76-9231-267ad3d34206)


Module Description: 

* Language: en

*  Map from text to 50-dimensional vectors

*  Based on NNLM with two hidden layers

*  Input preprocessed by splitting on spaces


References: 

* *A Neural Probabilistic Language Model*


Changelog: 

    None

## 6. universal-sentence-encoder

**The Universal Sentence Encoder encodes text into high dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks**

### 6.1 [universal-sentence-encoder@2](https://aihub.cloud.google.com/p/products%2F79c78579-2208-4f1c-ab08-c0d94f2adad1)


Module Description: 

* This module is about 1GB

*  output is a 512 dimensional vector


References: 

* *Universal Sentence Encoder*


Changelog: 

    <h4>Version 1</h4>

    <ul>

    <li>Initial release.</li>

    </ul>

    <h4>Version 2</h4>

    <ul>

    <li>Exposed internal variables as Trainable.</li>

    </ul>

    

### 6.2 [universal-sentence-encoder-large@3](https://aihub.cloud.google.com/p/products%2F42c1bfd4-8104-450c-a348-29b047d3691c)


Module Description: 

* This module is about 800MB

*  output is a 512 dimensional vector


References: 

* *Universal Sentence Encoder*


Changelog: 

    <h4>Version 1</h4>

    <ul>

    <li>Initial release.</li>

    </ul>

    <h4>Version 2</h4>

    <ul>

    <li>Exposed internal variables as Trainable.</li>

    </ul>

    <h4>Version 3</h4>

    <ul>

    <li>Fixed batch invariant <a href="https://github.com/tensorflow/hub/issues/74">bug</a>. This

       version was retrained and its embedding space differs from previous versions.</li>

    </ul>

    

### 6.3 [universal-sentence-encoder-lite@2](https://aihub.cloud.google.com/p/products%2Ffca281b8-15fd-4a79-824b-8f3228b40fa7)


Module Description: 

* lightweight version

*  output is a 512 dimensional vector


References: 

* *Universal Sentence Encoder*


Changelog: 

    <h4>Version 1</h4>

    <ul>

    <li>Initial release.</li>

    </ul>

    <h4>Version 2</h4>

    <ul>

    <li>Exposed internal variables as Trainable.</li>

    </ul>

    

## 7. universal-sentence-encoder-xling

**The Universal Sentence Encoder Cross-lingual (XLING) module is an extension of the Universal Sentence Encoder that includes training on multiple tasks across languages**

### 7.1 [universal-sentence-encoder-xling-en-de@1](https://aihub.cloud.google.com/p/products%2F5aa67e0e-389a-4ad7-bac6-fe1f705bc689)


Module Description: 

* English and German (en-de)

*  output is a 512 dimensional vector


References: 

* *Learning Cross-Lingual Sentence Representations via a Multi-task Dual-Encoder Model.*

* *Universal Sentence Encoder*


Changelog: 

    None

### 7.2 [universal-sentence-encoder-xling-en-es@1](https://aihub.cloud.google.com/p/products%2F774a1c7d-4426-41da-a964-b152fbe89c54)


Module Description: 

* English and Spanish (en-es)

*  output is a 512 dimensional vector


References: 

* *Learning Cross-Lingual Sentence Representations via a Multi-task Dual-Encoder Model.*

* *Universal Sentence Encoder*


Changelog: 

    None

### 7.3 [universal-sentence-encoder-xling-en-fr@1](https://aihub.cloud.google.com/p/products%2Fd7ba5172-43d6-4860-84b8-daa5165e766b)


Module Description: 

* English and French (en-fr)

*  output is a 512 dimensional vector


References: 

* *Learning Cross-Lingual Sentence Representations via a Multi-task Dual-Encoder Model.*

* *Universal Sentence Encoder*


Changelog: 

    None

### 7.4 [universal-sentence-encoder-xling-many@1](https://aihub.cloud.google.com/p/products%2F1c473955-f951-42cc-9191-df4e6dce0ceb)


Module Description: 

* English, French, German, Spanish, Italian, Chinese, Korean, and Japanese

*  output is a 512 dimensional vector


References: 

* *Learning Cross-Lingual Sentence Representations via a Multi-task Dual-Encoder Model.*

* *Universal Sentence Encoder*


Changelog: 

    None

