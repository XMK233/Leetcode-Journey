{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最主要成就：\n",
    "* 首当其冲的就是，这里实现了一套parse changelog的方法。什么基于etree的解析方法，都tnd不好用，还是简单粗暴的regular expression实用。真是搞得我太tnd不爽了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some necessary information from original code. \n",
    "\n",
    "And the code in the following cell comes from Get_Changelog.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n",
      "182\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "import os, json, md2py\n",
    "import os, shutil, re, json, tqdm\n",
    "from lxml import etree\n",
    "\n",
    "JSON_FILE = r\"J:\\ModelStoreData\\AIHub\\2019-06-04\\TFModule_Info.json\"\n",
    "\n",
    "def get_element_by_xpath(page_source, xpath, index = 0):\n",
    "    res = None\n",
    "    try:\n",
    "        _ = page_source.xpath(xpath)[index]\n",
    "        ## eliminate unnecessary chars.\n",
    "        _ = _.replace(\"\\n\", \"\").strip()\n",
    "        ## change the strings to lower case. Hopefully it will make the comparison standardized.\n",
    "        ## be careful about this change. If it is not suitable to the situation, stop it without hesitation.\n",
    "        _ = _.lower()\n",
    "        res = ' '.join(_.split())\n",
    "    except:\n",
    "        res = None\n",
    "    finally:\n",
    "        return res\n",
    "\n",
    "def parse_html_specially_for_imagenet(html, *args):\n",
    "    res = None\n",
    "    try:\n",
    "        page_source = etree.HTML(html)\n",
    "        author = get_element_by_xpath(page_source, \"//ul/li/text()\", args[0])\n",
    "        author = author.replace(\":\", \"\")\n",
    "        paper = get_element_by_xpath(page_source, \"//ul/li/a/text()\", args[1])\n",
    "        paper = paper.replace(\"\\\"\", \"\")\n",
    "        link_to_paper = get_element_by_xpath(page_source, \"//ul/li/a/@href\", args[2])\n",
    "        year = get_element_by_xpath(page_source, \"//ul/li/text()\", args[3])\n",
    "        year = re.findall(r\"(\\d{4})\", year)[0]\n",
    "        res = {\"author\": author, \"paper\": paper, \"link_to_paper\":link_to_paper, \"year\": year}\n",
    "    except:\n",
    "        print(f\"failed\")\n",
    "    finally:\n",
    "        return res\n",
    "    \n",
    "model_version_logInfo = {}\n",
    "model_logInfo = {}\n",
    "\n",
    "\n",
    "def Gather_md_code():\n",
    "    with open(JSON_FILE, \"r\") as jf:\n",
    "        items = json.load(jf)\n",
    "    counting_hangelog = 0\n",
    "    counting_ersion = 0\n",
    "    counting_other = 0\n",
    "    for item in items:\n",
    "        name = item[\"name\"]\n",
    "        version = item[\"version\"]\n",
    "        info = item[\"info\"]\n",
    "        link_url = \"https://aihub.cloud.google.com/p/products%2F{}/v/{}\".format(info[1][1].split(\"/\")[1], version)\n",
    "        md = info[1][7]\n",
    "        # toc = md2py.md2py(md)\n",
    "        # page_source = etree.HTML(str(toc.source))\n",
    "\n",
    "        ## lets' see whether they have c\"hangelog\" keywords.\n",
    "        if \"hangelog\" in md:\n",
    "            counting_hangelog += 1\n",
    "            toc1 = md2py.md2py(md.split(\"hangelog\")[1])\n",
    "            source_to_write = str(toc1.source)\n",
    "            remove_references = re.split(\"<h\\d>\\Seferences</h\\d>\", source_to_write)[0]\n",
    "\n",
    "            model_logInfo[name] = remove_references\n",
    "\n",
    "            if name not in model_version_logInfo:\n",
    "                model_version_logInfo[name] = {}  # [[version, str(toc1.source)]]\n",
    "                model_version_logInfo[name][version] = remove_references  # str(toc1.source)\n",
    "            else:\n",
    "                #                 model_version_logInfo[name].append([version, str(toc1.source)])\n",
    "                model_version_logInfo[name][version] = remove_references  # str(toc1.source)\n",
    "        #             print(str(toc1.source))\n",
    "        #             print(name, version, link_url)\n",
    "        else:\n",
    "            ## if there is no changelog keyword, let's see \"version\" keyword.\n",
    "            ## .. After manually checking out, no version/update/log.. info can be found.\n",
    "            if \"ersion\" in md:\n",
    "                counting_ersion += 1\n",
    "                # print(md, \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\")\n",
    "                # print(name, version, link_url)\n",
    "            else:\n",
    "                ## if neither \"ersion\" nor \"hangelog\" is available:\n",
    "                ## .. After manually checking out, no version/update/log.. info can be found.\n",
    "                counting_other += 1\n",
    "                # print(name, version, link_url)\n",
    "                # print(md, \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\")\n",
    "\n",
    "    print(counting_hangelog)\n",
    "    print(counting_ersion)\n",
    "    print(counting_other)\n",
    "\n",
    "\n",
    "Gather_md_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the necessary information from changelog html: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html_h4(html, *xpt):\n",
    "    versions = re.findall(xpt[0], html)\n",
    "    for i in range(len(versions)):\n",
    "        versions[i] = versions[i].replace(\"<h4>\", \"\").replace(\"</h4>\", \"\")\n",
    "    return versions\n",
    "\n",
    "def parse_html_ul_li(html, *xpt):\n",
    "    uls = re.findall(xpt[0], html)\n",
    "    list_of_list = []\n",
    "    for ul in uls:\n",
    "        lis = re.findall(xpt[1], ul)\n",
    "        for i in range(len(lis)):\n",
    "            lis[i] = \" \".join(lis[i].replace(\"<li>\", \"\").replace(\"</li>\", \"\").split())\n",
    "        list_of_list.append(lis)\n",
    "    return list_of_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the last version of each module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_latestVersion = {}\n",
    "for module in model_version_logInfo:\n",
    "    for version in model_version_logInfo[module]:\n",
    "        if module not in module_latestVersion:\n",
    "            module_latestVersion[module] = version\n",
    "        else:\n",
    "            module_latestVersion[module] = module_latestVersion[module] if module_latestVersion[module] > version else version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the module by change log. \n",
    "\n",
    "And the key of the __log_module__ will be each point of changelog. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_module = {}\n",
    "for module in module_latestVersion:\n",
    "    version = module_latestVersion[module]\n",
    "    changelog =  model_version_logInfo[module][version]\n",
    "    # parse_html(changelog.replace(\"\\n\", \"\"), \"//h4/text()\")\n",
    "    # parse_html(changelog.replace(\"\\n\", \"\"), \"//ul\", \"//li/text()\")\n",
    "    versions = parse_html_h4(changelog.replace(\"\\n\", \"\"), \"<h4>.*?</h4>\")\n",
    "    changelogs = parse_html_ul_li(changelog.replace(\"\\n\", \"\"), \"<ul>.*?</ul>\", \"<li>.*?</li>\")\n",
    "    for v, logs in zip(versions, changelogs):\n",
    "        for log in logs:\n",
    "            if log in log_module:\n",
    "                log_module[log][\"{}@{}\".format(module, v)] = -1   #.append((module, v))\n",
    "            else:\n",
    "                log_module[log] = {\"{}@{}\".format(module, v): -1}    # = [(module, v)]\n",
    "with open(\"log_module_v1.json\", \"w\") as lm:\n",
    "    json.dump(log_module, lm, indent= 4, sort_keys= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
